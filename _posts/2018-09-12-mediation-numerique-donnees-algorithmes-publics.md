---
title: Forum n°4 - Data.gouv.fr et les algorithmes à l’épreuve de la médiation numérique
categories: [news, updates]
---

Le quatrième forum Open d’Etat s’est tenu le 13 septembre 2018 à Nantes lors des rencontres Numérique en Commun[s] 

Le quatrième forum Open d’Etat s’est tenu le 13 septembre 2018 à Nantes lors des rencontres [Numérique en Commun\[s\]](https://www.numerique-en-commun.fr/) propulsées par la [mission Société Numérique](https://societenumerique.gouv.fr/) de l’agence du Numérique et [la coopérative de la médiation numérique](https://lamednum.coop/). Le forum s’est intéressé à deux engagements pris par la mission Etalab dans le cadre de la mise en oeuvre de la loi pour une République numérique. L’engagement 6 du [plan d’action national pour une action publique transparente et collaborative](https://www.etalab.gouv.fr/wp-content/uploads/2018/04/PlanOGP-FR-2018-2020-VF-FR.pdf) doit associer la société civile à l’étude des algorithmes publics pour en identifier les enjeux techniques, juridiques et organisationnels. En effet, la loi prévoit que chaque citoyen, lorsqu’une décision individuelle le concernant a été prise à son encontre à l’aide d’un algorithme puisse obtenir la communication sur demande des « règles » et « principales caractéristiques de mise en œuvre » de ce programme informatique, au regard de sa situation individuelle. L’engagement 4 du plan d’action prévoit de “poursuivre le développement de [data.gouv.fr2](http://data.gouv.fr) et y intégrer de nouvelles fonctionnalités” afin d’accroître l’utilité et l’impact des données ouvertes pour l’économie et la société. A partir d’octobre 2017, la loi impose un principe d’ouverture des données par défaut à toutes les administrations, tous les acteurs investis d’une mission de service public. L’inclusion de ce forum Open d’Etat au programme de Numérique en Commun\[s\] visait à s’appuyer sur la contribution des professionnels de la médiation numérique pour répondre à ces enjeux.

Comme pour chaque forum Open d’Etat, un kit d’appropriation a été transmis aux participants pour assurer une meilleure compréhension des enjeux et donner les éléments de contexte nécessaires. Le kit présente les grands principes du gouvernement ouvert et de l’open data, le contexte juridique de la transparence administrative, les enjeux de la transparence des algorithmes et de la “littératie” de données.

→ [Consulter le kit d’appropriation5](https://forum.etalab.gouv.fr/uploads/default/original/1X/ac539e23f9946855b915f0c64e5900d8a31a2e03.pdf)

Après un mot d’accueil de Laure Lucchesi, la directrice de la mission Etalab, quatre intervenants ont introduit les sujets de ce forum afin d’approfondir les enjeux traités dans les deux ateliers.

Dorie Bruyas (Fréquence Écoles) : les données publiques, trop arides pour la médiation en milieu scolaire
---------------------------------------------------------------------------------------------------------

Dorie Bruyas, la directrice de l’association [Fréquence Écoles](http://www.frequence-ecoles.org/), a présenté le travail de l’association en faveur de la compréhension des données par les jeunes. Pour en favoriser l’appropriation par le plus grand nombre, le cas des données publiques ouvertes semble être idéal lorsqu’il s’agit de développer des actions de médiation à la donnée. Or ces actions n’ont toujours été concluantes. Par exemple, pendant deux ans, des journalistes ont conduit des ateliers avec des lycéens sur les transports en région Rhône-Alpes. La majeure partie du temps du projet a consisté à nettoyer les données pour un résultat mitigé du point de vue de la réalisation finale mais riche d’enseignement en ce qui concerne le processus.

Fréquence Écoles s’est donc orientée vers des données plus familières des lycéens en travaillant sur les données de YouTube et non sur des données publiques. L’association a développé un jeu de cartes qui explique les mécanismes de l’algorithme de recommandation et le rôle des données dans l’évolution des recommandations. Fréquence Écoles a aussi présenté à Numérique en Commun une [cabane de médiation1](https://twitter.com/DorieBruyas/status/1042284386174083072) tangible autour des données qui sera aussi présentée les 16 et 17 décembre 2018 à [SuperDemain](https://www.superdemain.fr/). Elle recommande donc d’utiliser des données plus familières et ludiques pour faire de la médiation auprès d’un public jeune comme l’avait fait Simon Chignard dans un [atelier avec les données des prénoms](https://donneesouvertes.info/2012/10/10/infolab3-de-la-mode-et-des-prenoms/) ou Etalab dans son [calendrier de l’avent](https://avent.data.gouv.fr/).

Bénédicte Roullier (DINSIC) : avant la médiation, des principes pour une démarche en ligne réussie
--------------------------------------------------------------------------------------------------

Ensuite, Bénédicte Roullier, responsable qualité des services en ligne à la DINSIC (Direction Interministérielle du Numérique et du Système d’Information et de Communication de l’Etat), a présenté les [10 principes d’une démarche exemplaire1](http://www.modernisation.gouv.fr/outils-et-methodes-pour-transformer/les-10-principes-dune-demarche-en-ligne-exemplaire) pour apporter un éclairage sur les principes d’utilisabilité des services en ligne. Ces principes visent à améliorer la qualité de l’expérience utilisateur au moment où la personne fait sa démarche en ligne.

Parmi les facteurs de succès d’une démarche en ligne, la capacité à trouver facilement le bon lien vers la démarche est essentielle. Les cas d’arnaque aux démarches administratives sont révélatrices des problèmes de référencement et de visibilité des sites officiels. Une fois sur le bon site, le choix des mots est essentiel ainsi que la possibilité de disposer d’un espace de démonstration en bac à sable. Ce dernier permet à des médiateurs de montrer le fonctionnement de la démarche en ligne sans que la personne n’ait à exposer ses données personnelles ni à craindre une fausse manipulation.

Xavier Berne (NextINpact) : faire appliquer l’obligation d’explicitation des décisions prises par un algorithme
---------------------------------------------------------------------------------------------------------------

Troisième intervenant, Xavier Berne, journaliste chez NextINpact, un site dédié à l’actualité du numérique, a présenté [ses démarches](https://www.nextinpact.com/news/106986-obligation-dexplicitation-algorithmes-publics-an-pour-rien.htm) pour faire appliquer l’obligation de transparence et d’explicitation des algorithmes prévus par la loi pour une République Numérique. Il a signalé d’abord qu’il était impossible de trouver une mention explicite dans les sites et courriers officiels pour avertir les usagers qu’ils peuvent demander à se faire expliquer comment l’algorithme est intervenu dans une prise de décision les concernant. Il a fait des demandes d’explicitation des algorithmes auprès de l’administration fiscale, de Pôle Emploi et de la Caisse des Affaires Familiales. Seule cette dernière institution [s’est pliée à l’exercice1](https://www.nextinpact.com/news/105915-la-caf-repond-a-notre-demande-transparence-sur-lalgorithme-prime-dactivite.htm) sur la prime d’activité en détaillant la formule de calcul et en l’adaptant à sa situation personnelle.

Il a regretté que l’administration fiscale n’ait jamais répondu à sa demande d’explicitation malgré une décision favorable fin 2017 de la Commission d’accès aux documents administratifs (Cada) sur l’algorithme de calcul de la taxe d’habitation. Le code de source de ce dernier a été publié le lendemain par Etalab.

**Simon Chignard (Etalab) : les algorithmes, un élément indispensable et incontournable de la décision publique**
-----------------------------------------------------------------------------------------------------------------

Simon Chignard, conseiller stratégique d’Etalab, est d’abord revenu sur le rôle des algorithmes dans la sphère publique. Ils ciblent principalement des opérations répétitives, reproductives et qui concernent un grand nombre de cas, particulièrement dans le domaine socio-fiscal. Les algorithmes publics ont pour particularité d’être incontournables. Les algorithmes sont aussi très utilisés dans la gestion des ressources humaines (par exemple, le système de points pour la mutation des enseignants) et prennent parfois des décisions vitales comme [l’attribution des greffons](https://www.cairn.info/revue-francaise-des-affaires-sociales-2002-3-page-179.htm).

Lawrence Lessig avait montré que, dans certains domaines, le code informatique régule des secteurs avec la même force que la loi (“_code is law_”). Mais il est fréquent aussi que la loi devienne du code informatique (“_law is code_”). Est-ce que le code correspond aux dispositions prévues par loi ? Etalab a accompagné la Direction Générale des Finances Publiques (DGFIP) sur la publication du code source de la taxe d’habitation pour montrer qu’il y avait concordance entre les dispositions de la loi et l’algorithme. Dans le cas d’Admission Post Bac (APB), l’algorithme ne concordait pas totalement car la loi n’était pas assez précise. Les codeurs ont donc dû faire des choix. Par exemple, quand la demande excède l’offre, la loi dit qu’il faut tenir compte du domicile du candidat mais faut-il prendre en compte l’adresse de sa résidence universitaire ou celle de ses parents ? La transparence des algorithmes interroge le législateur : faut-il penser la loi pour qu’elle soit codable ?

Atelier A : tester des formats de médiation autour des algorithmes publics
--------------------------------------------------------------------------

L’atelier visait à tester des formats de médiation autour d’un traitement algorithmique particulier, celui du calcul de la taxe d’habitation. La [métaphore de la recette de cuisine](https://interstices.info/les-ingredients-des-algorithmes/#2) est fréquemment mobilisée dès qu’il s’agit d’expliquer le plus simplement possible ce qu’est un algorithme. Confronté à un exemple réel de recette de cuisine, les participants ont identifié la structure-type d’une recette de cuisine. La discussion avec les participants a permis d’identifier des correspondances entre les grands items qui composent une recette de cuisine et les [dispositions issues de la loi pour une République numérique sur la transparence des algorithmes](https://www.legifrance.gouv.fr/affichCodeArticle.do?cidTexte=LEGITEXT000031366350&idArticle=LEGIARTI000034195881) :

*   les ingrédients (et leur provenance) : les données traitées (et leur source),
*   les quantités : les paramètres, leur pondération appliquée à la situation de l’intéressé,
*   la progression de la recette : les opérations effectuées par le traitement.

La deuxième partie de l’atelier constituait en une mise en situation où les participants devaient comprendre comment a été calculé le montant de la taxe d’habitation qui leur a été réclamé. Il est ressorti que la valeur locative brute, spécifique à chaque logement, constitue l’ingrédient de base de la recette. C’est le point de départ du traitement, et le montant sur lequel sera calculé, après abattements, les taux d’imposition fixés par les différentes collectivités.

La dernière partie de l’atelier a été consacrée à la question de l’intelligibilité : comment rendre le calcul de la taxe compréhensible pour le plus grand nombre de foyers ? Une notice explicative, préparée par la DGFiP, a été présentée. Les participants ont imaginé d’autres formes de médiation possibles:

*   la feuille augmentée, avec des liens qui permettent de comprendre individuellement chaque élément et chaque étape de manière interactive ;
*   le re-design de l’avis pour mettre en avant les sources des données ;
*   une information sur la finalité de la taxe d’habitation et sur l’usage de l’impôt collecté ;
*   l’indication des acteurs qui interviennent dans la détermination des taux d’imposition (conseils municipaux, etc.) ;
*   le recours à un [simulateur](http://taxehabitation.etalab.studio/) comme celui développé par Marion Paclot (Etalab) qui permet de recalculer le montant de sa taxe d’habitation.

L’atelier a enfin permis d’identifier deux pistes pour rendre les algorithmes publics plus intelligibles pour ceux qui sont concernés par ces traitements.

*   La première consiste à restituer les données : l’administration communique à un individu l’ensemble des données qu’elle possède sur lui et qui interviennent dans un traitement algorithmique.
*   La seconde piste consiste à mieux contextualiser l’information fournie aux individus en fournissant des éléments permettant à un individu de se repérer, de comparer sa situation individuelle ou son territoire.

[Consulter le compte-rendu complet de l’atelier 1](https://forum.etalab.gouv.fr/uploads/default/original/1X/caf27f8012a97c66cc2ebb1f278d1b709d04cd51.pdf)
